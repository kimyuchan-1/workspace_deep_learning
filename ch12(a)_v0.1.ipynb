{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad290e35",
   "metadata": {},
   "source": [
    "# 타이타닉 생존자 예측 (v1)\n",
    "- 입력: 데이터의 독립변인 전부\n",
    "- 결과: 생존자를 예측(0 / 1)\n",
    "\n",
    "## 과정\n",
    "\n",
    "1. 데이터 불러오기\n",
    "2. 데이터 전처리\n",
    "3. 데이터 분할\n",
    "4. 데이터 정규화\n",
    "---\n",
    "5. 학습/검증/테스트 데이터(텐서로 변경해야 함)\n",
    "6. 모델 생성\n",
    "7. 학습\n",
    "8. 예측\n",
    "9. 평가\n",
    "\n",
    "> 주의: 5번부터는 PyTorch를 사용해서 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb042aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb41fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # print(f\"\\n결측치 : {df.isnull().sum()}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52b5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    target_col = \"Survived\"\n",
    "    columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    if \"Sex\" in df.columns:\n",
    "        df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})\n",
    "    if \"Embarked\" in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[\"Embarked\"], prefix=\"Embarked\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.to_list()\n",
    "    feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    X = X.fillna(X.mean())\n",
    "    return X.values, y.values, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05543b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_ratio=0.8):\n",
    "    n_samples = len(X)\n",
    "    n_train = int(n_samples * train_ratio)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    train_indices = indices[:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df1b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0) + 1e-8\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std\n",
    "    return X_train_norm, X_test_norm, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3877002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y) # 분류 문제라서 LongTensor 사용\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f011e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] 데이터 불러오기\n",
    "df = load_data(\"data/titanic/train.csv\")\n",
    "# [2] 데이터 전처리\n",
    "X, y, feature_cols = preprocess_data(df)\n",
    "# [3] 데이터 분할\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "# [4] 데이터 정규화\n",
    "X_train_norm, X_test_norm, mean, std = normalize_features(X_train, X_test)\n",
    "# [5] \n",
    "train_dataset = TitanicDataset(X_train_norm, y_train)\n",
    "test_dataset = TitanicDataset(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a86c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "279f4116",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
