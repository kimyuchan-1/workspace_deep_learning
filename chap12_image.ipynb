{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38be657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e6c3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pathlib.Path()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d74dd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/workspace_deep_learning')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d678e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/workspace_deep_learning/data/fruit')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = path / \"data\" / \"fruit\"\n",
    "p.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n",
      "<map object at 0x000001F01325A7D0>\n",
      "<map object at 0x000001F01325A530>\n"
     ]
    }
   ],
   "source": [
    "for i in p.iterdir():\n",
    "    list(i.glob(\"**/*.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383c833",
   "metadata": {},
   "source": [
    "1. 이미지 경로를 설정\n",
    "2. 디렉토리 이름을 별도로 가져와야 함\n",
    "3. 각 디렉토리에 맞춰서 이미지를 관리해야 함\n",
    "4. 이미지를 텐서로 변경해야 함 (레이블을 추가해야 함)\n",
    "5. 전체 이미지를 7:2:1(학습, 검증, 테스트) 나눠야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "edac2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a8d3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a61df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(root_dir):\n",
    "    root_path = Path(root_dir)\n",
    "    # 클래스(레이블) 생성\n",
    "    classes = sorted([d.name for d in root_path.iterdir() if d.is_dir()])\n",
    "    class_to_idx = {class_name : idx for idx, class_name in enumerate(classes)}\n",
    "    idx_to_class = {idx : class_name for idx, class_name in enumerate(classes)}\n",
    "\n",
    "    # 이미지 파일 수집\n",
    "    images = []\n",
    "    labels = []\n",
    "    for cls_name in classes:\n",
    "        cls_dir = root_path / cls_name\n",
    "        for img_path in cls_dir.glob(\"*.jpg\"):\n",
    "            images.append(img_path)\n",
    "            labels.append(class_to_idx[cls_name])\n",
    "\n",
    "    return images, labels, class_to_idx, idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a9e5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(image_size=64, augment=True):\n",
    "    if augment:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "    else :\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98b3c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "084f3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(image, label, train_ratio = 0.8):\n",
    "    n_sample = len(image)\n",
    "    n_train = int(n_sample * train_ratio)\n",
    "\n",
    "    indices = np.random.permutation(n_sample)\n",
    "    train_indices = indices[:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "\n",
    "    train_images = [image[i] for i in train_indices]\n",
    "    val_images = [image[i] for i in test_indices]\n",
    "    train_labels = [label[i] for i in train_indices]\n",
    "    val_labels = [label[i] for i in test_indices] \n",
    "\n",
    "    return train_images, val_images, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bfd06ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu를 사용합니다.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/fruit\"\n",
    "max_epochs = 3\n",
    "batch_size = 32\n",
    "image_size = 64\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = get_device()\n",
    "print(f'{device}를 사용합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d65cca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, class_to_idx, idx_to_class = load_data(data_dir)\n",
    "train_images, val_images, train_labels, val_labels = split_data(images, labels)\n",
    "transform_train = get_transform(image_size, augment=True)\n",
    "transform_val = get_transform(image_size, augment=False)\n",
    "\n",
    "train_dataset = FruitDataset(train_images, train_labels, transform_train)\n",
    "val_dataset = FruitDataset(val_images, val_labels, transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624bceff",
   "metadata": {},
   "source": [
    "# 14장에 나오는 CNN을 해야 합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fce0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
