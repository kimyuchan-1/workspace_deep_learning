{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad290e35",
   "metadata": {},
   "source": [
    "# 타이타닉 생존자 예측 (v1)\n",
    "\n",
    "- 입력: 데이터의 독립변인 전부 (작은게 좋음)\n",
    "- 결과: 생존자를 예측(0 / 1)\n",
    "\n",
    "## 과정\n",
    "\n",
    "1. 데이터 불러오기\n",
    "2. 데이터 전처리\n",
    "3. 데이터 분할\n",
    "4. 데이터 정규화\n",
    "---\n",
    "5. 학습/검증/테스트 데이터(텐서로 변경해야 함)\n",
    "6. 모델 생성(a. 베이스라인, b. 개선)\n",
    "7. 학습\n",
    "8. 예측\n",
    "9. 평가\n",
    "\n",
    "> 주의: 5번부터는 PyTorch를 사용해서 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb042aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb41fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 형태(행, 열 크기)\n",
    "    # - 열(독립변인, 측정값)\n",
    "    # - 행(종속변인, 관측값)\n",
    "    # 자료형(info)\n",
    "    # 컬럼이름\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52b5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    target_col = \"Survived\"\n",
    "    columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    if \"Sex\" in df.columns:\n",
    "        df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})\n",
    "    if \"Embarked\" in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[\"Embarked\"], prefix=\"Embarked\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.to_list()\n",
    "    feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    X = X.fillna(X.mean())\n",
    "    return X.values, y.values, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05543b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_ratio=0.8):\n",
    "    n_samples = len(X)\n",
    "    n_train = int(n_samples * train_ratio)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    train_indices = indices[:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df1b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0) + 1e-8\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std\n",
    "    return X_train_norm, X_test_norm, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3877002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y) # 분류 문제라서 LongTensor 사용\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d02d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LinearClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassificationModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1150e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        acc = 100 * correct / total\n",
    "        loss_history.append(avg_loss)\n",
    "        acc_history.append(acc)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"{epoch+1} : {avg_loss}, {acc}\")\n",
    "    return loss_history, acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f011e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] 데이터 불러오기\n",
    "df = load_data(\"data/titanic/train.csv\")\n",
    "# [2] 데이터 전처리\n",
    "X, y, feature_cols = preprocess_data(df)\n",
    "# [3] 데이터 분할\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "# [4] 데이터 정규화\n",
    "X_train_norm, X_test_norm, mean, std = normalize_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854a86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5a] \n",
    "train_dataset = TitanicDataset(X_train_norm, y_train)\n",
    "test_dataset = TitanicDataset(X_test_norm, y_test)\n",
    "# [5b]\n",
    "batch_size = 32 # 하이퍼 파라미터(a)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 초기 데이터의 크기와 결과에 대해서 미리 알고 있어야 함\n",
    "input_dim = X_train_norm.shape[1]\n",
    "num_classes = 2\n",
    "model = LinearClassificationModel(input_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce38de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 0.5189841260080752, 77.9494382022472\n",
      "20 : 0.4718442507412123, 78.23033707865169\n",
      "30 : 0.45304796877114667, 79.21348314606742\n",
      "40 : 0.4460901112660118, 79.35393258426966\n",
      "50 : 0.4425584809935611, 79.49438202247191\n",
      "60 : 0.44347754509552667, 79.21348314606742\n",
      "70 : 0.4503637591133947, 79.49438202247191\n",
      "80 : 0.4404614813949751, 79.49438202247191\n",
      "90 : 0.44180770283160004, 79.21348314606742\n",
      "100 : 0.4476490467786789, 79.49438202247191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6455990983092267,\n",
       "  0.6214880710062773,\n",
       "  0.6022348948146986,\n",
       "  0.5892752473768981,\n",
       "  0.564428132513295,\n",
       "  0.5505003851392994,\n",
       "  0.5453239951444708,\n",
       "  0.5328584559585737,\n",
       "  0.5256781694681748,\n",
       "  0.5189841260080752,\n",
       "  0.5101650862590127,\n",
       "  0.5094598790873652,\n",
       "  0.49903669823770935,\n",
       "  0.4928934457509414,\n",
       "  0.4892320257166158,\n",
       "  0.4832260582758033,\n",
       "  0.4823308263135993,\n",
       "  0.4958657803742782,\n",
       "  0.4759669770365176,\n",
       "  0.4718442507412123,\n",
       "  0.48019252782282623,\n",
       "  0.4796934425830841,\n",
       "  0.47388859676278156,\n",
       "  0.4642861964909927,\n",
       "  0.47025074129519256,\n",
       "  0.46833237487336865,\n",
       "  0.4581053995567819,\n",
       "  0.4690203018810438,\n",
       "  0.4570896871711897,\n",
       "  0.45304796877114667,\n",
       "  0.47488500760949176,\n",
       "  0.46349727589151135,\n",
       "  0.4545773034510405,\n",
       "  0.4591495420621789,\n",
       "  0.4668999638246453,\n",
       "  0.4519225151642509,\n",
       "  0.45835418156955554,\n",
       "  0.4635588060254636,\n",
       "  0.4543311479298965,\n",
       "  0.4460901112660118,\n",
       "  0.46214729417925293,\n",
       "  0.45038784457289655,\n",
       "  0.45611301712367847,\n",
       "  0.45036738851796027,\n",
       "  0.4568336593068164,\n",
       "  0.45018661540487537,\n",
       "  0.44989193522411847,\n",
       "  0.4513146242369776,\n",
       "  0.44729888568753784,\n",
       "  0.4425584809935611,\n",
       "  0.4430166638415793,\n",
       "  0.44902761993200885,\n",
       "  0.446111640204554,\n",
       "  0.4532316858353822,\n",
       "  0.44418087472086365,\n",
       "  0.45038521808126697,\n",
       "  0.4582551069881605,\n",
       "  0.4527088481446971,\n",
       "  0.44914664133735327,\n",
       "  0.44347754509552667,\n",
       "  0.44110687724922015,\n",
       "  0.45211708286534186,\n",
       "  0.4424160563427469,\n",
       "  0.4510697048643361,\n",
       "  0.4425203184718671,\n",
       "  0.45051879856897437,\n",
       "  0.44958604677863745,\n",
       "  0.447112456611965,\n",
       "  0.4439648260240969,\n",
       "  0.4503637591133947,\n",
       "  0.4620030600091685,\n",
       "  0.4470378834268321,\n",
       "  0.452939730623494,\n",
       "  0.44466307759284973,\n",
       "  0.4663582729256671,\n",
       "  0.44061219497867254,\n",
       "  0.447530878626782,\n",
       "  0.4445104119570359,\n",
       "  0.4493014825427014,\n",
       "  0.4404614813949751,\n",
       "  0.4483979201835135,\n",
       "  0.441896611581678,\n",
       "  0.44822060543557873,\n",
       "  0.4411153061234433,\n",
       "  0.43911578603412793,\n",
       "  0.4462859863820283,\n",
       "  0.4560658219067947,\n",
       "  0.4440434795358907,\n",
       "  0.4629616879898569,\n",
       "  0.44180770283160004,\n",
       "  0.44734859466552734,\n",
       "  0.4400044187255528,\n",
       "  0.452779876149219,\n",
       "  0.45054812923721643,\n",
       "  0.45118068352989527,\n",
       "  0.45124619551326917,\n",
       "  0.4433861050916755,\n",
       "  0.457937593045442,\n",
       "  0.4485080034836479,\n",
       "  0.4476490467786789],\n",
       " [70.78651685393258,\n",
       "  74.85955056179775,\n",
       "  76.54494382022472,\n",
       "  77.24719101123596,\n",
       "  77.6685393258427,\n",
       "  77.52808988764045,\n",
       "  77.24719101123596,\n",
       "  77.6685393258427,\n",
       "  78.08988764044943,\n",
       "  77.9494382022472,\n",
       "  77.80898876404494,\n",
       "  77.6685393258427,\n",
       "  77.6685393258427,\n",
       "  77.80898876404494,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.23033707865169,\n",
       "  78.37078651685393,\n",
       "  78.65168539325843,\n",
       "  78.79213483146067,\n",
       "  78.79213483146067,\n",
       "  79.07303370786516,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.35393258426966,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.35393258426966,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.35393258426966,\n",
       "  79.63483146067416,\n",
       "  79.49438202247191,\n",
       "  79.35393258426966,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.35393258426966,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.21348314606742,\n",
       "  79.07303370786516,\n",
       "  79.07303370786516,\n",
       "  79.21348314606742,\n",
       "  79.07303370786516,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.07303370786516,\n",
       "  79.21348314606742,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.49438202247191,\n",
       "  79.63483146067416,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.35393258426966,\n",
       "  79.21348314606742,\n",
       "  79.21348314606742,\n",
       "  79.63483146067416,\n",
       "  79.49438202247191,\n",
       "  79.63483146067416,\n",
       "  79.49438202247191,\n",
       "  79.49438202247191,\n",
       "  79.63483146067416,\n",
       "  79.49438202247191,\n",
       "  79.35393258426966,\n",
       "  79.49438202247191])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f4116",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
