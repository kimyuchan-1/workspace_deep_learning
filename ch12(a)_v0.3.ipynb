{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad290e35",
   "metadata": {},
   "source": [
    "# 타이타닉 생존자 예측 (v1)\n",
    "\n",
    "- 입력: 데이터의 독립변인 전부 (작은게 좋음)\n",
    "- 결과: 생존자를 예측(0 / 1)\n",
    "\n",
    "## 과정\n",
    "\n",
    "1. 데이터 불러오기\n",
    "2. 데이터 전처리\n",
    "3. 데이터 분할\n",
    "4. 데이터 정규화\n",
    "---\n",
    "5. 학습/검증/테스트 데이터(텐서로 변경해야 함)\n",
    "6. 모델 생성(a. 베이스라인, b. 개선)\n",
    "7. 학습\n",
    "8. 예측\n",
    "9. 평가\n",
    "\n",
    "> 주의: 5번부터는 PyTorch를 사용해서 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eb042aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeb41fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 형태(행, 열 크기)\n",
    "    # - 열(독립변인, 측정값)\n",
    "    # - 행(종속변인, 관측값)\n",
    "    # 자료형(info)\n",
    "    # 컬럼이름\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a52b5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    target_col = \"Survived\"\n",
    "    columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    if \"Sex\" in df.columns:\n",
    "        df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})\n",
    "    if \"Embarked\" in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[\"Embarked\"], prefix=\"Embarked\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.to_list()\n",
    "    feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    X = X.fillna(X.mean())\n",
    "    return X.values, y.values, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05543b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_ratio=0.8):\n",
    "    n_samples = len(X)\n",
    "    n_train = int(n_samples * train_ratio)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    train_indices = indices[:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5df1b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0) + 1e-8\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std\n",
    "    return X_train_norm, X_test_norm, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3877002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y) # 분류 문제라서 LongTensor 사용\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d02d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LinearClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassificationModel, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),            \n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),              \n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1150e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        acc = 100 * correct / total\n",
    "        loss_history.append(avg_loss)\n",
    "        acc_history.append(acc)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"{epoch+1} : {avg_loss}, {acc}\")\n",
    "    return loss_history, acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "930ac1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            pred = model(batch_X)\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            predictions.extend(predicted.numpy())\n",
    "            actuals.extend(batch_y.numpy())\n",
    "            \n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    print(f\"\\n=== 테스트 세트 평가 ===\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Correct: {correct}/{total}\")\n",
    "    \n",
    "    return predictions, actuals, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45f011e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] 데이터 불러오기\n",
    "df = load_data(\"data/titanic/train.csv\")\n",
    "# [2] 데이터 전처리\n",
    "X, y, feature_cols = preprocess_data(df)\n",
    "# [3] 데이터 분할\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "# [4] 데이터 정규화\n",
    "X_train_norm, X_test_norm, mean, std = normalize_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "854a86c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 0.4288137768921645, 81.60112359550561\n",
      "20 : 0.432538909756619, 82.4438202247191\n",
      "30 : 0.4322083760862765, 82.7247191011236\n",
      "40 : 0.4027125291202379, 84.41011235955057\n",
      "50 : 0.39380335678224976, 83.42696629213484\n",
      "60 : 0.3870399704445963, 84.69101123595506\n",
      "70 : 0.3984350173369698, 82.86516853932584\n",
      "80 : 0.37969425255837647, 84.5505617977528\n",
      "90 : 0.3675023038750109, 84.69101123595506\n",
      "100 : 0.3830209847377694, 84.26966292134831\n",
      "\n",
      "=== 테스트 세트 평가 ===\n",
      "Accuracy: 81.01%\n",
      "Correct: 145/179\n"
     ]
    }
   ],
   "source": [
    "# [5a] \n",
    "train_dataset = TitanicDataset(X_train_norm, y_train)\n",
    "test_dataset = TitanicDataset(X_test_norm, y_test)\n",
    "# [5b]\n",
    "batch_size = 32 # 하이퍼 파라미터(a)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# [6]\n",
    "input_dim = X_train_norm.shape[1]\n",
    "num_classes = 2\n",
    "model = LinearClassificationModel(input_dim, num_classes)\n",
    "\n",
    "# [7]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_history, acc_history = train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# [8]\n",
    "predictions, actuals, accuracy = evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce38de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "279f4116",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
