{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ab1e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9233ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # 한 번에 병렬로 처리할 시퀀스의 수\n",
    "block_size = 128 # 예측을 위한 최대 컨텍스트 길이\n",
    "max_iters = 1000\n",
    "eval_interval = 200\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a481dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x187f3e09510>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcac953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩\n",
    "# 데이터를 처음 조직하는 방법은 반드시 알고 있어야 함\n",
    "# BE -> N+1 문제 -> 왜 생기는가? -> JPA\n",
    "# DATA -> Size, Len\n",
    "class DataHandler:\n",
    "    '''\n",
    "    데이터 로드해야 함\n",
    "    문자 -> 숫자\n",
    "    숫자 -> 문자\n",
    "    '''\n",
    "    def __init__(self, block_size, batch_size):\n",
    "        self.block_size = block_size\n",
    "        self.batch_size = batch_size\n",
    "        # 파일 읽어오기\n",
    "        with open(\"data/tiny_shakespeare.txt\") as f:\n",
    "            self.text = f.read()\n",
    "\n",
    "        # 고유 문자 집합 및 매핑\n",
    "        self.chars = sorted(list(set(self.text)))\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.stoi = {ch:i for i, ch in enumerate(self.chars)}\n",
    "        self.itos = {i:ch for i, ch in enumerate(self.chars)}\n",
    "\n",
    "        # 데이터 분할(학습, 검증)\n",
    "        data = torch.tensor(self.encoder(self.text), dtype=torch.long)\n",
    "        n = int(0.9 * len(data))\n",
    "        self.train_data = data[:n]\n",
    "        self.val_data = data[n:]\n",
    "\n",
    "    def encoder(self, s):\n",
    "        # 문자 > 숫자\n",
    "        return [self.stoi[c] for c in s]\n",
    "\n",
    "    def decoder(self, l):\n",
    "        # 숫자 > 문자\n",
    "        return \"\".join([self.itos[i] for i in l])\n",
    "\n",
    "    def get_batch(self, split):\n",
    "        data = self.train_data if split == \"train\" else self.val_data\n",
    "        ix = torch.randint(len(data) - self.block_size, (self.batch_size))\n",
    "        x = torch.stack([data[i:i+self.block_size] for i in ix])\n",
    "        y = torch.stack([data[i+1:i+self.block_size] for i in ix])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f4112e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, data_path, block_size, batch_size, device):\n",
    "        self.block_size = block_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        \n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            self.text = f.read()\n",
    "\n",
    "        self.chars = sorted(list(set(self.text)))\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.stoi = { ch:i for i,ch in enumerate(self.chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(self.chars) }\n",
    "        \n",
    "        data = torch.tensor(self.encode(self.text), dtype=torch.long)\n",
    "        n = int(0.9*len(data))\n",
    "        self.train_data = data[:n]\n",
    "        self.val_data = data[n:]\n",
    "\n",
    "    def encode(self, s):\n",
    "        return [self.stoi[c] for c in s]\n",
    "\n",
    "    def decode(self, l):\n",
    "        return ''.join([self.itos[i] for i in l])\n",
    "\n",
    "    def get_batch(self, split):\n",
    "        data = self.train_data if split == 'train' else self.val_data\n",
    "        ix = torch.randint(len(data) - self.block_size, (self.batch_size,))\n",
    "        x = torch.stack([data[i:i+self.block_size] for i in ix])\n",
    "        y = torch.stack([data[i+1:i+self.block_size+1] for i in ix])\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eff16e",
   "metadata": {},
   "source": [
    "## 셀프 어텐션 메커니즘\n",
    "\n",
    "### 같은 시퀸스 내에 단어들 간의 관계\n",
    "\n",
    "> 기존: 인코더와 디코더의 사이 관계\n",
    "\n",
    "> 셀프: 같은 시퀸스\n",
    "\n",
    "- 문장에서 단어의 의미는 주변에 따라 결정\n",
    "- 셀프 어텐션 계산\n",
    "    1. 입력 준비(각 단어가 벡터)\n",
    "    2. 유사도 계산\n",
    "    3. 가중치 계산\n",
    "    4. 문맥 벡터 생성\n",
    "\n",
    "- 훈련 가능한 어텐션 메커니즘: 점곱 어텐션\n",
    "    - Q: \"무엇을 찾고 있어요?\" - 현재 단어가 찾는 것\n",
    "    - K: \"무엇을 제공할 수 있어요?\"\n",
    "    - V: \"실제로 사용할 값\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 128\n",
    "dropout = 0.1\n",
    "block_size= 128\n",
    "class Head(nn.Module):\n",
    "    # Self-Attention의 단일 헤드(one head)\n",
    "    def __init__(self, head_size):\n",
    "        super(Head, self).__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        '''...'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac413c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        \n",
    "        v = self.value(x)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbc4961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3201f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cd5d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92631986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # 1. 토큰 임베딩 테이블: 각 문자를 벡터로 변환\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        # 2. 포지션 임베딩 테이블: 위치 정보를 벡터로 변환\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        # 3. 트랜스포머 블록들\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        # 4. 최종 Layer Normalization\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        # 5. 최종 선형 계층 (Logits 생성)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cbca702",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, data_handler):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = data_handler.get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9878ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_handler):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for iter in range(max_iters):\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss(model, data_handler)\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        xb, yb = data_handler.get_batch('train')\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"학습 완료. (Training finished.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "960f2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 1. 데이터 준비\n",
    "    data_handler = DataHandler('./data/tiny_shakespeare.txt', block_size, batch_size, device)\n",
    "    print(f\"Vocab size: {data_handler.vocab_size}\")\n",
    "    \n",
    "    # 2. 모델 초기화\n",
    "    model = GPTLanguageModel(data_handler.vocab_size)\n",
    "    m = model.to(device)\n",
    "    print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "    # 3. 학습 수행\n",
    "    train_model(m, data_handler)\n",
    "    \n",
    "    # 4. 생성 (Generation)\n",
    "    print(\"생성된 텍스트 샘플 (Generated sample):\")\n",
    "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    generated_indices = m.generate(context, max_new_tokens=500)[0].tolist()\n",
    "    print(generated_indices)\n",
    "    print(data_handler.decode(generated_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5785e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Vocab size: 65\n",
      "0.824897 M parameters\n",
      "step 0: train loss 4.3037, val loss 4.3055\n",
      "step 200: train loss 2.4406, val loss 2.4435\n",
      "step 400: train loss 2.2260, val loss 2.2523\n",
      "step 600: train loss 2.0182, val loss 2.0801\n",
      "step 800: train loss 1.8942, val loss 1.9937\n",
      "step 999: train loss 1.8051, val loss 1.9364\n",
      "학습 완료. (Training finished.)\n",
      "생성된 텍스트 샘플 (Generated sample):\n",
      "[0, 32, 53, 1, 50, 39, 63, 1, 52, 53, 40, 50, 43, 1, 44, 53, 56, 1, 46, 47, 57, 1, 45, 53, 1, 46, 43, 39, 1, 57, 46, 39, 50, 57, 1, 42, 47, 42, 43, 42, 1, 57, 59, 41, 46, 5, 42, 0, 13, 1, 41, 39, 50, 50, 58, 47, 43, 52, 58, 1, 58, 46, 43, 1, 56, 43, 43, 54, 57, 6, 1, 40, 43, 1, 63, 53, 59, 58, 1, 42, 53, 1, 57, 46, 43, 51, 47, 50, 50, 42, 57, 8, 1, 35, 39, 56, 1, 44, 47, 56, 5, 57, 1, 58, 46, 43, 52, 43, 57, 0, 32, 39, 63, 1, 40, 50, 43, 1, 40, 43, 1, 52, 53, 58, 43, 57, 58, 1, 39, 52, 42, 57, 58, 39, 52, 58, 1, 57, 58, 47, 43, 45, 1, 46, 43, 52, 47, 45, 39, 50, 43, 0, 27, 1, 44, 47, 45, 46, 58, 47, 56, 1, 42, 53, 1, 58, 46, 43, 39, 1, 47, 58, 6, 1, 61, 47, 50, 50, 42, 39, 52, 42, 1, 46, 47, 52, 42, 1, 58, 53, 1, 57, 58, 47, 42, 43, 1, 40, 43, 1, 40, 50, 39, 41, 49, 1, 42, 43, 1, 57, 43, 43, 54, 0, 13, 52, 42, 1, 47, 58, 1, 39, 1, 61, 43, 56, 58, 1, 47, 44, 1, 46, 39, 51, 43, 1, 58, 46, 43, 1, 46, 47, 51, 1, 52, 53, 1, 51, 53, 58, 1, 58, 53, 1, 46, 43, 1, 58, 53, 61, 0, 40, 59, 56, 42, 1, 43, 43, 1, 46, 43, 52, 43, 6, 1, 43, 1, 63, 53, 59, 45, 46, 1, 41, 53, 52, 45, 50, 39, 50, 42, 1, 39, 58, 1, 51, 39, 50, 40, 50, 43, 1, 53, 39, 56, 51, 43, 8, 0, 15, 59, 54, 50, 43, 2, 1, 57, 43, 43, 56, 43, 6, 1, 46, 43, 1, 46, 53, 59, 1, 61, 53, 59, 58, 1, 57, 43, 43, 54, 1, 46, 53, 1, 45, 53, 53, 42, 61, 39, 63, 6, 1, 47, 52, 11, 0, 13, 52, 1, 47, 51, 53, 59, 45, 39, 1, 52, 39, 58, 50, 39, 63, 8, 0, 0, 16, 33, 25, 10, 0, 21, 5, 50, 63, 6, 1, 5, 32, 46, 43, 1, 39, 51, 6, 1, 58, 39, 47, 56, 11, 1, 21, 1, 46, 43, 1, 42, 56, 43, 43, 57, 41, 39, 60, 43, 1, 53, 44, 1, 51, 47, 57, 46, 39, 58, 43, 1, 47, 57, 1, 5, 53, 61, 1, 58, 46, 53, 6, 0, 20, 63, 1, 57, 53, 52, 6, 1, 46, 39, 42, 0, 35, 46, 39, 58, 1, 41, 39, 58, 1, 40, 43, 39, 60, 43, 1, 58, 46, 63, 8, 1, 32, 46, 39, 58, 1, 61, 46, 39, 50, 50, 1, 39, 1, 51, 63, 1, 34, 47, 58, 46, 39, 58, 46, 43, 56, 6, 1, 39, 52, 39]\n",
      "\n",
      "To lay noble for his go hea shals dided such'd\n",
      "A calltient the reeps, be yout do shemillds. War fir's thenes\n",
      "Tay ble be notest andstant stieg henigale\n",
      "O fightir do thea it, willdand hind to stide be black de seep\n",
      "And it a wert if hame the him no mot to he tow\n",
      "burd ee hene, e yough conglald at malble oarme.\n",
      "Cuple! seere, he hou wout seep ho goodway, in;\n",
      "An imouga natlay.\n",
      "\n",
      "DUM:\n",
      "I'ly, 'The am, tair; I he dreescave of mishate is 'ow tho,\n",
      "Hy son, had\n",
      "What cat beave thy. That whall a my Vithather, ana\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4179438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from transformers) (3.20.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from transformers) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2026.1.15-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from requests->transformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\torch2\\lib\\site-packages (from requests->transformers) (2026.1.4)\n",
      "Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.0 MB 5.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/12.0 MB 5.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.7/12.0 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/12.0 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.3/12.0 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.7/12.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 6.5 MB/s  0:00:01\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 8.0 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.8/2.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 9.8 MB/s  0:00:00\n",
      "Downloading regex-2026.1.15-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [tokenizers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   ---------------------------------------- 5/5 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.36.0 regex-2026.1.15 safetensors-0.7.0 tokenizers-0.22.2 transformers-4.57.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
